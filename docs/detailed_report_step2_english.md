# Detailed Report - Step 2: Model Development and Evaluation

## Executive Summary

This report presents the comprehensive model development and evaluation for cefiderocol resistance prediction. Three classification models were developed and compared: Logistic Regression, Random Forest, and XGBoost. The models were trained on data from 2014-2018 and evaluated on 2019 data to ensure temporal validation.

## Key Results

- **Best Model**: XGBoost (AUC: 0.798)
- **Training Data**: 2014-2018 (38,288 isolates)
- **Test Data**: 2019 (9,327 isolates)
- **Total Features**: 11 engineered features

## 1. Feature Engineering and Selection

### 1.1 Selected Features

**Base Features:**
- **MIC Values**: meropenem_mic, CIPROFLOXACIN_mic, colistin_mic
- **Categorical**: species_encoded, region_encoded
- **Temporal**: year

**Engineered Features:**
- **Logarithmic Transformations**: log_meropenem, log_ciprofloxacin, log_colistin
- **Interactions**: meropenem_ciprofloxacin, meropenem_colistin

### 1.2 Data Split Strategy

**Temporal Split**: This approach ensures realistic evaluation by testing on future data, which is crucial for clinical applications.

- **Training Set (2014-2018)**: 38,288 isolates (98.2% sensitive, 1.8% resistant)
- **Test Set (2019)**: 9,327 isolates (97.3% sensitive, 2.7% resistant)

## 2. Model Development

### 2.1 Implemented Models

**1. Logistic Regression**
- **Type**: Linear classification model
- **Advantages**: Interpretable, fast training
- **Limitations**: Assumes linear relationships

**2. Random Forest**
- **Type**: Ensemble of decision trees
- **Advantages**: Handles non-linear relationships, feature importance
- **Limitations**: Less interpretable than linear models

**3. XGBoost**
- **Type**: Gradient boosting ensemble
- **Advantages**: High performance, handles missing values
- **Limitations**: Complex, requires careful tuning

## 3. Model Performance Results

### 3.1 Comparative Performance

| Model | AUC | Precision | Recall | CV AUC (5-fold) |
|-------|-----|-----------|--------|-----------------|
| **Logistic Regression** | 0.794 | 0.000 | 0.000 | 0.836 Â± 0.063 |
| **Random Forest** | 0.717 | 0.200 | 0.072 | 0.811 Â± 0.066 |
| **XGBoost** | 0.798 | 0.409 | 0.036 | 0.870 Â± 0.058 |

### 3.2 Best Performing Model: XGBoost

ðŸ† **XGBoost Achievements:**
- **Highest AUC**: 0.798 on test set
- **Best Cross-Validation**: 0.870 Â± 0.058
- **Best Precision**: 0.409 (highest among all models)

### 3.3 Performance Analysis

âš ï¸ **Class Imbalance Challenge**
The low recall values across all models (0.000-0.072) indicate a significant class imbalance problem. Only 1.8-2.7% of isolates are resistant, making it difficult for models to learn the minority class patterns.

## 4. Model Evaluation Visualizations

### 4.1 ROC Curves and Precision-Recall Analysis

![Model Evaluation Curves](outputs/plots/model_evaluation.png)

*Left: ROC curves showing the trade-off between true positive rate and false positive rate. Right: Precision-Recall curves showing the relationship between precision and recall for different threshold values.*

### 4.2 Feature Importance Analysis

![Feature Importance Analysis](outputs/plots/feature_importance.png)

*Comparison of feature importance across the three models. This analysis reveals which variables are most predictive of cefiderocol resistance.*

### 4.3 SHAP Analysis

![SHAP Analysis](outputs/plots/shap_analysis.png)

*SHAP (SHapley Additive exPlanations) analysis for the XGBoost model, showing how each feature contributes to the prediction of cefiderocol resistance.*

## 5. Key Insights and Interpretations

### 5.1 Model Performance Insights

1. **XGBoost Superiority**: XGBoost achieved the highest AUC (0.798) and best cross-validation performance (0.870), indicating robust generalization.
2. **Precision vs Recall Trade-off**: While XGBoost has the highest precision (0.409), all models struggle with recall due to class imbalance.
3. **Cross-Validation Stability**: XGBoost shows the most stable cross-validation results with the lowest standard deviation.

### 5.2 Clinical Implications

1. **High Precision**: When XGBoost predicts resistance, it's correct 40.9% of the time, which is clinically valuable for treatment decisions.
2. **Low Recall**: The model misses many resistant cases, suggesting the need for additional features or different approaches.
3. **AUC > 0.7**: All models show acceptable discrimination ability, with XGBoost approaching good performance (AUC > 0.8).

## 6. Recommendations for Improvement

### 6.1 Addressing Class Imbalance

- **Resampling Techniques**: Implement SMOTE, ADASYN, or other oversampling methods
- **Class Weights**: Adjust class weights in model training
- **Ensemble Methods**: Combine multiple models with different sampling strategies

### 6.2 Feature Engineering

- **Additional MIC Features**: Include more antibiotic susceptibility data from ATLAS dataset
- **Clinical Features**: Add patient demographics, infection site, previous antibiotic use
- **Temporal Features**: Create time-based features and trends

### 6.3 Model Optimization

- **Hyperparameter Tuning**: Use grid search or Bayesian optimization
- **Threshold Optimization**: Optimize classification thresholds for clinical needs
- **Ensemble Methods**: Combine predictions from multiple models

## 7. Conclusion

âœ… **Step 2 Successfully Completed**

- XGBoost emerged as the best performing model with an AUC of 0.798 and the highest precision of 0.409.
- The temporal validation approach ensures realistic performance estimates for clinical applications.
- Class imbalance remains a significant challenge that needs to be addressed in future iterations.

### Next Steps

1. **Address Class Imbalance**: Implement resampling techniques and class weights
2. **Feature Expansion**: Integrate additional data from ATLAS dataset
3. **Model Optimization**: Perform hyperparameter tuning and threshold optimization
4. **Clinical Validation**: Validate model performance in real-world clinical settings

---

**Report Generated**: July 2025  
**Data Sources**: SIDERO-WT (1.xlsx), ATLAS (2.xlsx)  
**Analysis Tools**: Python, scikit-learn, XGBoost, SHAP  
**Total Isolates Analyzed**: 47,615 (38,288 training + 9,327 test) 